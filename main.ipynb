{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =YOLO('model=/home/marwa/MaskDetectionYolo8/yolov8m.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.66 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.8.10 torch-1.7.0+cu101 CUDA:0 (NVIDIA GeForce GTX 1080, 8111MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=model=/home/marwa/MaskDetectionYolo8/yolov8m.pt, data=/home/marwa/Self Driving Caryolov8/data.yaml, epochs=50, patience=50, batch=1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolovm_train, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/yolovm_train3\n",
      "Overriding model.yaml nc=80 with nc=11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3782065  ultralytics.nn.modules.Detect                [11, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25862689 parameters, 25862673 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/marwa/Self Driving Caryolov8/train/labels.cache... 14942 images, 1760 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/marwa/Self Driving Caryolov8/train/images/1478021875081281646_jpg.rf.8c4543dd08bca5a4fabf316839199939.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/marwa/Self Driving Caryolov8/train/images/1478897760163798179_jpg.rf.78469943f7d410430540cfedfb748048.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/marwa/Self Driving Caryolov8/train/images/1478898145212453716_jpg.rf.ce94c47338bbc3066cb5fa5aacc1c720.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/marwa/Self Driving Caryolov8/val/labels.cache... 58 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/yolovm_train3/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/yolovm_train3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50     0.895G      1.463      1.313      1.185         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [28:37<00:00,  8.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 17.50it/s]\n",
      "                   all         58        308      0.613      0.236      0.257      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50     0.942G      1.457      1.125      1.175         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [27:52<00:00,  8.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 17.61it/s]\n",
      "                   all         58        308      0.597      0.239      0.264      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50     0.944G      1.516      1.219      1.214         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [27:20<00:00,  9.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 17.74it/s]\n",
      "                   all         58        308      0.601      0.217      0.242       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50     0.944G      1.542      1.242      1.252          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [27:54<00:00,  8.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 17.67it/s]\n",
      "                   all         58        308      0.599      0.229       0.25      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50     0.944G      1.519      1.187      1.249          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [27:20<00:00,  9.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 17.73it/s]\n",
      "                   all         58        308      0.619      0.228      0.256      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50     0.944G      1.491       1.13      1.233         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [27:17<00:00,  9.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 17.65it/s]\n",
      "                   all         58        308       0.61      0.221       0.25      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50     0.944G      1.462      1.095       1.22         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [27:18<00:00,  9.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 17.79it/s]\n",
      "                   all         58        308      0.942      0.231      0.253      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50     0.944G      1.457      1.062      1.221          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [27:17<00:00,  9.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 17.69it/s]\n",
      "                   all         58        308      0.597      0.238      0.255      0.163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50     0.944G      1.428      1.021      1.205          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14942/14942 [27:17<00:00,  9.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 17.72it/s]\n",
      "                   all         58        308      0.947      0.239      0.259      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50     0.944G      1.412      1.001      1.193          1        640:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 8100/14942 [15:06<14:00,  8.14it/s]"
     ]
    }
   ],
   "source": [
    "model.train(data='/home/marwa/Self Driving Caryolov8/data.yaml', epochs=50, imgsz=640, name='yolovm_train', batch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.8.10 torch-1.7.0+cu101 CUDA:0 (NVIDIA GeForce GTX 1080, 8111MiB)\n",
      "Model summary (fused): 218 layers, 25846129 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/marwa/Self Driving Caryolov8/val/labels.cache... 58 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.41s/it]\n",
      "                   all         58        308      0.747      0.289      0.283      0.191\n",
      "                   car         58        297      0.791      0.778        0.8      0.527\n",
      "            pedestrian         58          1          1          0          0          0\n",
      "                 truck         58         10      0.449     0.0897     0.0495     0.0445\n",
      "Speed: 6.0ms preprocess, 22.7ms inference, 0.0ms loss, 42.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 1,  2, 10])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x7f4079924dc0>\n",
       "fitness: 0.19992265510251372\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.19067,     0.52749,           0,     0.19067,     0.19067,     0.19067,     0.19067,     0.19067,     0.19067,     0.19067,     0.04453])\n",
       "names: {0: 'biker', 1: 'car', 2: 'pedestrian', 3: 'trafficLight', 4: 'trafficLight-Green', 5: 'trafficLight-GreenLeft', 6: 'trafficLight-Red', 7: 'trafficLight-RedLeft', 8: 'trafficLight-Yellow', 9: 'trafficLight-YellowLeft', 10: 'truck'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.7466209585584993, 'metrics/recall(B)': 0.28931910524282833, 'metrics/mAP50(B)': 0.2831619242966095, 'metrics/mAP50-95(B)': 0.19067384741428084, 'fitness': 0.19992265510251372}\n",
       "save_dir: PosixPath('runs/detect/val2')\n",
       "speed: {'preprocess': 5.971074104309082, 'inference': 22.68603752399313, 'loss': 0.0006577064251077587, 'postprocess': 42.70866410485629}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('/home/marwa/Self Driving Caryolov8/runs/detect/yolovm_train3/weights/best.pt')\n",
    "model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "\n",
      "0: 384x640 10 cars, 4 pedestrians, 15.3ms\n",
      "Speed: 0.6ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 7 pedestrians, 14.0ms\n",
      "Speed: 0.6ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 6 pedestrians, 13.8ms\n",
      "Speed: 0.6ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 5 pedestrians, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 4 pedestrians, 14.7ms\n",
      "Speed: 0.6ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 5 pedestrians, 12.7ms\n",
      "Speed: 0.5ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 5 pedestrians, 12.7ms\n",
      "Speed: 0.9ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 pedestrians, 13.4ms\n",
      "Speed: 0.5ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 pedestrians, 12.7ms\n",
      "Speed: 0.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.1ms\n",
      "Speed: 0.5ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 12.2ms\n",
      "Speed: 0.7ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 4 pedestrians, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 12.2ms\n",
      "Speed: 0.5ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.3ms\n",
      "Speed: 0.5ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 5 pedestrians, 12.2ms\n",
      "Speed: 0.5ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 12.2ms\n",
      "Speed: 0.5ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 4 pedestrians, 13.4ms\n",
      "Speed: 0.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.1ms\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.5ms\n",
      "Speed: 0.6ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 pedestrians, 12.2ms\n",
      "Speed: 0.5ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.3ms\n",
      "Speed: 0.5ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 13.3ms\n",
      "Speed: 0.5ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 4 pedestrians, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 13.5ms\n",
      "Speed: 0.6ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.3ms\n",
      "Speed: 0.6ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 12.5ms\n",
      "Speed: 0.5ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 15 cars, 3 pedestrians, 12.3ms\n",
      "Speed: 0.9ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 13.1ms\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 4 pedestrians, 13.1ms\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 4 pedestrians, 12.6ms\n",
      "Speed: 0.7ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 12.1ms\n",
      "Speed: 0.5ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.2ms\n",
      "Speed: 0.5ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.4ms\n",
      "Speed: 0.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.3ms\n",
      "Speed: 0.5ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 13.3ms\n",
      "Speed: 0.5ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 3 pedestrians, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 pedestrians, 13.0ms\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.9ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.8ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.2ms\n",
      "Speed: 0.5ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.0ms\n",
      "Speed: 0.7ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 13.3ms\n",
      "Speed: 0.5ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 13.1ms\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 12.7ms\n",
      "Speed: 0.7ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 12.2ms\n",
      "Speed: 0.5ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 3 pedestrians, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.7ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.2ms\n",
      "Speed: 0.7ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.3ms\n",
      "Speed: 0.6ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.2ms\n",
      "Speed: 0.7ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 pedestrians, 13.3ms\n",
      "Speed: 0.7ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 pedestrians, 12.7ms\n",
      "Speed: 0.5ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 pedestrians, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.1ms\n",
      "Speed: 0.5ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.4ms\n",
      "Speed: 0.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 pedestrians, 12.4ms\n",
      "Speed: 0.6ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 pedestrians, 12.3ms\n",
      "Speed: 0.5ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 17 cars, 2 pedestrians, 12.2ms\n",
      "Speed: 0.5ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 pedestrians, 12.3ms\n",
      "Speed: 0.8ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 pedestrians, 13.4ms\n",
      "Speed: 0.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.4ms\n",
      "Speed: 0.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.1ms\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 13.3ms\n",
      "Speed: 0.6ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 pedestrians, 13.1ms\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.5ms\n",
      "Speed: 0.6ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 pedestrians, 20.5ms\n",
      "Speed: 1.4ms preprocess, 20.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 pedestrians, 12.5ms\n",
      "Speed: 0.5ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.4ms\n",
      "Speed: 0.7ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.8ms\n",
      "Speed: 0.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.7ms\n",
      "Speed: 0.5ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.1ms\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.4ms\n",
      "Speed: 0.6ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 13.2ms\n",
      "Speed: 0.6ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 19.5ms\n",
      "Speed: 0.7ms preprocess, 19.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.8ms\n",
      "Speed: 0.6ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 13.5ms\n",
      "Speed: 0.6ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.5ms\n",
      "Speed: 0.6ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 12.8ms\n",
      "Speed: 0.7ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 12.8ms\n",
      "Speed: 0.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 12.5ms\n",
      "Speed: 0.7ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 13.2ms\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 13.1ms\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.8ms\n",
      "Speed: 0.6ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 13.4ms\n",
      "Speed: 0.6ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 12.8ms\n",
      "Speed: 0.5ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 13.1ms\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.7ms\n",
      "Speed: 0.7ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.8ms\n",
      "Speed: 0.6ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 13.4ms\n",
      "Speed: 0.6ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 pedestrian, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 pedestrian, 13.3ms\n",
      "Speed: 0.6ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.8ms\n",
      "Speed: 0.6ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.6ms\n",
      "Speed: 0.8ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.7ms\n",
      "Speed: 0.5ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 12.9ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 12.2ms\n",
      "Speed: 0.5ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 13.5ms\n",
      "Speed: 0.5ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 12.9ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 13.1ms\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 pedestrian, 13.3ms\n",
      "Speed: 0.5ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.7ms\n",
      "Speed: 0.7ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 12.9ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.8ms\n",
      "Speed: 0.7ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 15.5ms\n",
      "Speed: 0.7ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.3ms\n",
      "Speed: 0.6ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 13.1ms\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 12.3ms\n",
      "Speed: 0.5ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 13.0ms\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 12.7ms\n",
      "Speed: 0.5ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.3ms\n",
      "Speed: 0.5ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.4ms\n",
      "Speed: 0.6ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 pedestrians, 13.4ms\n",
      "Speed: 0.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 13.3ms\n",
      "Speed: 0.5ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 pedestrian, 12.7ms\n",
      "Speed: 0.5ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.1ms\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 12.5ms\n",
      "Speed: 0.6ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 12.7ms\n",
      "Speed: 0.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 8 cars, 12.5ms\n",
      "Speed: 0.6ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 6 cars, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 cars, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 pedestrian, 13.3ms\n",
      "Speed: 0.6ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 cars, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.8ms\n",
      "Speed: 0.6ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 pedestrian, 12.7ms\n",
      "Speed: 0.9ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 pedestrian, 13.2ms\n",
      "Speed: 0.6ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.5ms\n",
      "Speed: 0.6ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.8ms\n",
      "Speed: 0.5ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.3ms\n",
      "Speed: 0.5ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.1ms\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.5ms\n",
      "Speed: 0.5ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.4ms\n",
      "Speed: 0.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 pedestrians, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 pedestrians, 13.3ms\n",
      "Speed: 0.6ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 pedestrians, 12.4ms\n",
      "Speed: 0.5ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 3 pedestrians, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 3 pedestrians, 12.4ms\n",
      "Speed: 0.7ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 3 pedestrians, 13.2ms\n",
      "Speed: 0.6ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 pedestrians, 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 12.5ms\n",
      "Speed: 0.5ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 pedestrian, 13.0ms\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 pedestrian, 12.8ms\n",
      "Speed: 0.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 pedestrian, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 12.6ms\n",
      "Speed: 0.7ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 pedestrians, 13.3ms\n",
      "Speed: 0.5ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 pedestrians, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 pedestrians, 12.5ms\n",
      "Speed: 0.5ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 pedestrian, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 pedestrians, 12.5ms\n",
      "Speed: 0.5ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 pedestrians, 12.3ms\n",
      "Speed: 0.5ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 pedestrians, 12.4ms\n",
      "Speed: 0.6ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 pedestrians, 13.5ms\n",
      "Speed: 0.6ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------done--------------------\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "\n",
    "test='/home/marwa/Self Driving Caryolov8/test'\n",
    "img='1478020363197149061.jpg'\n",
    "model = '/home/marwa/Self Driving Caryolov8/runs/detect/yolovm_train2/weights/best.pt'\n",
    "video_path = os.path.join(test, 'video2.mp4')\n",
    "video_path_out = '{}_out.mp4'.format(video_path)\n",
    "frames_path = '/home/marwa/Self Driving Caryolov8/test/frames2'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "H, W, _ = frame.shape\n",
    "out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (640,640))\n",
    "\n",
    "img_path = os.path.join(test,img)\n",
    "model = YOLO(model)\n",
    "thrsld = 0.1\n",
    "class_name_dict = {0: 'biker', 1: 'car', 2: 'pedestrian', 3: 'trafficLight', 4: 'trafficLight-Green', 5: 'trafficLight-GreenLeft', 6: 'trafficLight-Red', 7: 'trafficLight-RedLeft', 8: 'trafficLight-Yellow', 9: 'trafficLight-YellowLeft', 10: 'truck'}\n",
    "colors = [(89, 161, 197),(67, 161, 255),(19, 222, 24),(186, 55, 2),(167, 146, 11),(190, 76, 98),(130, 172, 179),(115, 209, 128),(204, 79, 135),(136, 126, 185),(209, 213, 45),(44, 52, 10),(101, 158, 121),(179, 124, 12),(25, 33, 189),(45, 115, 11),(73, 197, 184),(62, 225, 221),(32, 46, 52),(20, 165, 16),(54, 15, 57),(12, 150, 9),(10, 46, 99),(94, 89, 46),(48, 37, 106),(42, 10, 96),(7, 164, 128),(98, 213, 120),(40, 5, 219),(54, 25, 150),(251, 74, 172),(0, 236, 196),(21, 104, 190),(226, 74, 232),(120, 67, 25),(191, 106, 197),(8, 15, 134),(21, 2, 1),(142, 63, 109),(133, 148, 146),(187, 77, 253),(155, 22, 122),(218, 130, 77),(164, 102, 79),(43, 152, 125),(185, 124, 151),(95, 159, 238),(128, 89, 85),(228, 6, 60),(6, 41, 210),(11, 1, 133),(30, 96, 58),(230, 136, 109),(126, 45, 174),(164, 63, 165),(32, 111, 29),(232, 40, 70),(55, 31, 198),(148, 211, 129),(10, 186, 211),(181, 201, 94),(55, 35, 92),(129, 140, 233),(70, 250, 116),(61, 209, 152),(216, 21, 138),(100, 0, 176),(3, 42, 70),(151, 13, 44),(216, 102, 88),(125, 216, 93),(171, 236, 47),(253, 127, 103),(205, 137, 244),(193, 137, 224),(36, 152, 214),(17, 50, 238),(154, 165, 67),(114, 129, 60),(119, 24, 48),(73, 8, 110)]\n",
    "\n",
    "i=0\n",
    "cars=0\n",
    "while ret:\n",
    "    results = model.predict(frame, hide_labels=False, show=True, imgsz=640)[0]\n",
    "    # x1, y1, x2, y2, score, class_id = result\n",
    "    # boxes = torch.tensor([x1,y1,x2,y2])\n",
    "    # scores = torch.tensor(score)\n",
    "    # nms(boxes=boxes, scores=scores, iou_threshold=0.2)\n",
    "    # print(results)\n",
    "    if ret==True:\n",
    "        for result in results.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = result\n",
    "            label = \"{}:{:.2f}\".format(class_name_dict[int(class_id)], score)\n",
    "            lw = max(round(sum(frame.shape) / 2 * 0.003), 2)\n",
    "            p1, p2 = (int(x1), int(y1)), (int(x2), int(y2))\n",
    "            color = colors[int(class_id)]\n",
    "            cv2.rectangle(frame, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
    "            tf = max(lw - 1, 1)  # font thickness\n",
    "            w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n",
    "            outside = p1[1] - h >= 3\n",
    "            p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "            frame = cv2.rectangle(frame, p1, p2, color, -1, cv2.LINE_AA)            \n",
    "            frame = cv2.putText(frame,label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),0,lw / 3,(255,255,255),thickness=tf,lineType=cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "    out.write(frame)\n",
    "    frame_name = 'Frame'+str(i)+'.jpg'\n",
    "    cv2.imwrite(os.path.join(frames_path,frame_name), frame)\n",
    "    i+=1\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"-------------done--------------------\")\n",
    "\n",
    "\n",
    "# results = model.predict(img_path, hide_labels=False, show=True, imgsz=512)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame number.............. ['/home/marwa/Self Driving Caryolov8/test/frames/Frame0.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame1.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame2.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame3.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame4.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame5.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame6.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame7.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame8.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame9.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame10.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame11.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame12.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame13.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame14.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame15.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame16.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame17.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame18.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame19.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame20.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame21.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame22.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame23.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame24.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame25.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame26.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame27.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame28.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame29.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame30.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame31.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame32.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame33.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame34.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame35.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame36.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame37.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame38.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame39.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame40.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame41.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame42.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame43.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame44.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame45.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame46.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame47.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame48.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame49.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame50.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame51.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame52.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame53.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame54.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame55.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame56.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame57.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame58.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame59.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame60.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame61.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame62.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame63.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame64.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame65.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame66.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame67.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame68.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame69.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame70.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame71.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame72.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame73.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame74.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame75.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame76.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame77.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame78.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame79.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame80.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame81.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame82.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame83.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame84.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame85.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame86.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame87.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame88.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame89.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame90.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame91.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame92.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame93.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame94.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame95.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame96.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame97.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame98.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame99.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame100.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame101.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame102.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame103.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame104.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame105.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame106.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame107.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame108.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame109.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame110.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame111.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame112.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame113.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame114.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame115.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame116.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame117.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame118.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame119.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame120.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame121.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame122.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame123.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame124.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame125.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame126.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame127.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame128.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame129.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame130.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame131.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame132.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame133.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame134.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame135.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame136.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame137.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame138.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame139.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame140.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame141.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame142.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame143.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame144.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame145.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame146.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame147.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame148.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame149.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame150.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame151.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame152.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame153.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame154.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame155.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame156.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame157.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame158.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame159.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame160.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame161.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame162.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame163.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame164.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame165.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame166.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame167.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame168.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame169.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame170.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame171.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame172.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame173.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame174.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame175.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame176.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame177.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame178.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame179.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame180.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame181.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame182.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame183.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame184.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame185.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame186.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame187.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame188.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame189.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame190.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame191.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame192.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame193.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame194.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame195.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame196.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame197.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame198.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame199.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame200.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame201.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame202.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame203.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame204.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame205.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame206.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame207.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame208.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame209.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame210.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame211.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame212.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame213.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame214.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame215.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame216.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame217.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame218.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame219.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame220.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame221.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame222.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame223.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame224.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame225.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame226.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame227.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame228.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame229.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame230.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame231.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame232.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame233.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame234.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame235.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame236.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame237.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame238.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame239.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame240.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame241.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame242.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame243.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame244.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame245.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame246.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame247.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame248.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame249.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame250.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame251.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame252.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame253.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame254.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame255.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame256.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame257.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame258.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame259.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame260.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame261.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame262.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame263.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame264.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame265.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame266.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame267.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame268.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame269.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame270.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame271.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame272.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame273.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame274.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame275.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame276.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame277.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame278.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame279.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame280.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame281.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame282.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame283.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame284.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame285.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame286.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame287.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame288.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame289.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame290.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame291.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame292.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame293.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame294.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame295.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame296.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame297.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame298.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame299.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame300.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame301.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame302.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame303.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame304.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame305.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame306.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame307.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame308.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame309.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame310.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame311.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame312.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame313.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame314.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame315.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame316.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame317.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame318.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame319.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame320.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame321.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame322.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame323.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame324.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame325.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame326.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame327.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame328.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame329.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame330.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame331.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame332.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame333.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame334.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame335.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame336.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame337.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame338.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame339.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame340.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame341.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame342.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame343.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame344.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame345.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame346.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame347.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame348.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame349.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame350.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame351.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame352.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame353.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame354.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame355.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame356.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame357.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame358.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame359.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame360.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame361.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame362.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame363.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame364.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame365.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame366.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame367.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame368.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame369.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame370.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame371.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame372.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame373.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame374.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame375.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame376.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame377.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame378.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame379.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame380.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame381.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame382.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame383.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame384.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame385.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame386.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame387.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame388.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame389.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame390.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame391.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame392.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame393.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame394.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame395.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame396.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame397.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame398.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame399.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame400.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame401.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame402.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame403.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame404.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame405.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame406.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame407.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame408.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame409.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame410.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame411.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame412.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame413.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame414.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame415.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame416.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame417.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame418.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame419.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame420.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame421.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame422.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame423.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame424.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame425.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame426.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame427.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame428.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame429.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame430.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame431.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame432.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame433.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame434.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame435.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame436.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame437.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame438.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame439.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame440.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame441.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame442.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame443.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame444.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame445.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame446.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame447.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame448.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame449.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame450.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame451.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame452.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame453.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame454.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame455.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame456.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame457.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame458.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame459.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame460.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame461.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame462.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame463.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame464.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame465.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame466.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame467.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame468.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame469.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame470.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame471.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame472.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame473.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame474.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame475.jpg', '/home/marwa/Self Driving Caryolov8/test/frames/Frame476.jpg']\n",
      "sequence clip <moviepy.video.io.ImageSequenceClip.ImageSequenceClip object at 0x7f6a0bc6dcd0>\n",
      "Moviepy - Building video myvideo.mp4.\n",
      "Moviepy - Writing video myvideo.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready myvideo.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import natsort\n",
    "img_path = '/home/marwa/Self Driving Caryolov8/test/frames'\n",
    "video_path = '/home/marwa/Self Driving Caryolov8/test/video.mp3'\n",
    "img_array = []\n",
    "from moviepy.editor import *\n",
    "import moviepy.video.io.ImageSequenceClip\n",
    "image_folder=img_path\n",
    "fps=1\n",
    "\n",
    "image_files = [os.path.join(image_folder,img)\n",
    "                for img in natsort.natsorted(os.listdir(image_folder))]\n",
    "\n",
    "# image_files= image_files[0:100]\n",
    "print(\"frame number..............\",image_files)\n",
    "clip = ImageSequenceClip(image_files, fps=10)\n",
    "print(\"sequence clip\",clip)\n",
    "# clip = ImageSequenceClip([os.path.join(img_path,'Frame0.jpg'), os.path.join(img_path,'Frame1.jpg'),os.path.join(img_path,'Frame2.jpg'),os.path.join(img_path,'Frame3.jpg'),os.path.join(img_path,'Frame4.jpg'),os.path.join(img_path,'Frame5.jpg')\n",
    "#                           ,os.path.join(img_path,'Frame6.jpg'),os.path.join(img_path,'Frame7.jpg'),os.path.join(img_path,'Frame8.jpg'),os.path.join(img_path,'Frame9.jpg'),os.path.join(img_path,'Frame10.jpg'),os.path.join(img_path,'Frame11.jpg')],fps=1)\n",
    "# print(clip)\n",
    "\n",
    "clip.write_videofile('myvideo.mp4')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
